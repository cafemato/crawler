{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=UTF-8\n",
    "# ver 3.0(加入function，抓取內頁，輸入資料庫的資料做預處理以便後續的Chart.JS)\n",
    "##目標網址:104人力銀行，搜尋關鍵字[大數據]\n",
    "##利用xpath取得資料後,以sqlalchemy與pandas連結mysql送入資料\n",
    "import requests\n",
    "from lxml import etree\n",
    "from fake_useragent import UserAgent\n",
    "import pandas\n",
    "from sqlalchemy import create_engine\n",
    "import mysql.connector\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import pymysql\n",
    "#Part 1.輸入框輸入要搜尋的關鍵字keyword之後，會自動去搜尋職缺並存入資料庫\n",
    "   \n",
    "\n",
    "#爬蟲主程式，輸入搜尋關鍵字keyword以及指定table名稱t_name兩參數後，開始爬蟲\n",
    "def crawler(keyword,t_name):   \n",
    "    ua = UserAgent()\n",
    "    j = 1\n",
    "    job_list = []\n",
    "    while True:    \n",
    "        headers = {'user-agent':ua.random}\n",
    "        url = keyword_url(keyword)\n",
    "        final_url = url + str(j)\n",
    "    #   列印抓取的頁數\n",
    "        print(final_url)\n",
    "        res = requests.get(final_url, headers = headers)\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "        #所有職缺的總區塊\n",
    "        data = soup.find_all(\"article\", class_=\"b-block--top-bord job-list-item b-clearfix js-job-item\")     \n",
    "        if len(data) == 0:     #   如果抓不到資料就停止\n",
    "            break\n",
    "        for i in range(len(data)):\n",
    "            try:\n",
    "                position = data[i].find(\"a\").text.strip()            \n",
    "                company = data[i].find(\"ul\").find(\"a\").text.strip()\n",
    "                area = data[i].find(\"ul\",class_=\"b-list-inline b-clearfix job-list-intro b-content\").find_all(\"li\")[0].text.strip()\n",
    "                industry = data[i].attrs['data-indcat-desc'].strip()     \n",
    "                if any(x in industry for x in ['金融','銀行業','保險','投資',\"證券\"]):\n",
    "                    industry = \"金融業\"\n",
    "                elif any(x in industry for x in [\"電腦\",\"軟體\",\"硬體\",\"系統\",\"網路\"]):\n",
    "                    industry = \"資訊科技業\"\n",
    "                elif any(x in industry for x in [\"半導體\",\"電信\",\"電子\",\"光電\"]):\n",
    "                    industry = \"電子電信業\"\n",
    "                elif  any(x in industry for x in [\"製造\",\"食品\",\"飲料\",\"紡織\",\"家具\",\"製紙\",\"印刷\",\"化工\",\"金屬\",\"機械\",\"電力\",\"運輸\",\"儀器\",\"建築\",\"物流\",\"倉儲\",\"營建\",\"品管\",\"品保\",\"土木\",\"農林漁牧\",\"礦業土石\"]):\n",
    "                    industry = \"傳產製造業\"\n",
    "                elif  any(x in industry for x in [\"出版\",\"翻譯\",\"影視\",\"演藝\",\"新聞\",\"媒體\",\"美編\",\"設計\",\"裝潢\",\"傳播\"]):\n",
    "                    industry = \"文化媒體業\"\n",
    "                elif  any(x in industry for x in [\"教育\",\"研究\",\"醫\",\"生化\",\"生技\"]):\n",
    "                    industry = \"教育研究醫療生技業\"\n",
    "                elif  any(x in industry for x in [\"經營\",\"零售\",\"管理\",\"行政\",\"行銷\",\"企劃\",\"顧問\",\"財務\",\"會計\",\"稽核\",\"審計\",\"國際貿易\",\"業務\",\"客服\"]):\n",
    "                    industry = \"一般商業\"\n",
    "                elif  any(x in industry for x in [\"美容\",\"美髮\",\"餐飲\",\"烘培\",\"觀光\",\"旅遊\",\"門市\"]):\n",
    "                    industry = \"服務業\"  \n",
    "                else:\n",
    "                    industry = \"其他產業\" \n",
    "                requirement = data[i].find(\"ul\",class_=\"b-list-inline b-clearfix job-list-intro b-content\").find_all(\"li\")[1].text.strip()\n",
    "                if requirement == \"經歷不拘\": \n",
    "                    requirement = 'N'\n",
    "                else:\n",
    "                    requirement = requirement.split(\"年以上\")[0]\n",
    "                education = data[i].find(\"ul\",class_=\"b-list-inline b-clearfix job-list-intro b-content\").find_all(\"li\")[2].text.strip()\n",
    "                content = data[i].find(\"p\",class_=\"job-list-item__info b-clearfix b-content\").text.strip()\n",
    "                salary_low = data[i].find(\"div\",class_=\"job-list-tag b-content\").find(\"span\").text.strip()\n",
    "                if salary_low  == \"待遇面議\": \n",
    "                    salary_low = 'N/A'\n",
    "                    salary_high = ''\n",
    "                elif \"元以上\" in salary_low:\n",
    "                    salary_low = ''.join(x for x in salary_low if x.isdigit())\n",
    "                    salary_high = ''\n",
    "                elif \"~\" in salary_low :\n",
    "                    low = salary_low.split(\"~\")[0]\n",
    "                    high = salary_low.split(\"~\")[1]\n",
    "                    salary_low = ''.join(x for x in low if x.isdigit())\n",
    "                    salary_high = ''.join(x for x in high if x.isdigit())                  \n",
    "                updated = data[i].find(\"h2\",class_=\"b-tit\").find(\"span\").text.strip()\n",
    "                applicant = data[i].find(\"div\",class_=\"b-block__right b-pos-relative\").find(\"a\").text.strip()\n",
    "                link =  data[i].find(\"h2\").find(\"a\").attrs['href'].strip()\n",
    "                job_url = \"https:\" + link\n",
    "                res2 = requests.get(job_url, headers = headers)\n",
    "                soup = BeautifulSoup(res2.text, \"html.parser\")\n",
    "                detail = soup.find(\"div\", id=\"job\")\n",
    "                job_type = detail.find_all(\"div\",class_=\"content\")[0].find_all(\"dd\")[2].text.strip()\n",
    "                b_trip = detail.find_all(\"div\",class_=\"content\")[0].find_all(\"dd\")[5].text.strip()\n",
    "                if b_trip == \"無需出差外派\":\n",
    "                    b_trip = 'N'\n",
    "                else:\n",
    "                     b_trip = 'Y'\n",
    "                manager = detail.find_all(\"div\",class_=\"content\")[0].find_all(\"dd\")[4].text.strip()\n",
    "                if manager == \"不需負擔管理責任\":\n",
    "                    manager = 'N'\n",
    "                else:\n",
    "                     manager = 'Y'\n",
    "                language = detail.find_all(\"div\",class_=\"content\")[1].find_all(\"dd\")[4].text.strip()\n",
    "                if language == \"不拘\":\n",
    "                    language = \"N\"\n",
    "                else:\n",
    "                    language = language.split(\"--\")[0].strip()\n",
    "                soft_skill = detail.find_all(\"div\",class_=\"content\")[1].find_all(\"dd\")[5].text.strip()\n",
    "                other_skill = detail.find_all(\"div\",class_=\"content\")[1].find_all(\"dd\")[6].text.strip()                        \n",
    "                job_list.append({\"bank_id\":\"104\",\"company\":company,\"position\":position,\"area\":area,\"salary_low\":salary_low, \"salary_high\":salary_high, \"industry\":industry,\n",
    "                                    \"requirement\":requirement,\"education\":education,\"content\":content,\"applicant\":applicant,\"updated\":updated,\n",
    "                                 \"link\":job_url,\"job_type\":job_type, \"b_trip\":b_trip, \"manager\":manager, \"language\":language, \"soft_skill\":soft_skill,\n",
    "                                 \"other_skill\":other_skill }) \n",
    "            except:\n",
    "                continue                        \n",
    "        j +=1\n",
    "#     隨機休眠5~15秒後再執行下一頁的抓取\n",
    "#     time.sleep(random.randrange(3,10))\n",
    "    return job_list\n",
    "\n",
    "#將關鍵字併入搜尋url\n",
    "def keyword_url(keyword):\n",
    "    url = \"https://www.104.com.tw/jobs/search/?ro=0&keyword=\" + keyword + \"&order=1&asc=0&page=\"    \n",
    "    return url \n",
    "# print(keyword_url(\"大數據\"))\n",
    "\n",
    "#輸入table名稱t_name後建立關鍵字對應的table\n",
    "def check_table_exist(t_name):\n",
    "    conn = pymysql.connect(host = \"127.0.0.1\", user = \"root\", passwd = \"root\" , db = \"job_bank\")\n",
    "    #查詢前，必須先獲取游標\n",
    "    cursor = conn.cursor()\n",
    "    #先確認資料庫內有無此table\n",
    "    stmt = \"SHOW TABLES LIKE \\'\" +  t_name + \"\\'\"\n",
    "    cursor.execute(stmt)\n",
    "    result = cursor.fetchone()\n",
    "    if result:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def create_table(t_name, new=1):\n",
    "    conn = pymysql.connect(host = \"127.0.0.1\", user = \"root\", passwd = \"root\" , db = \"job_bank\")\n",
    "    #查詢前，必須先獲取游標\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    table_start = ''' CREATE TABLE IF NOT EXISTS '''\n",
    "    table_end = '''(\\\n",
    "   `id` int(10) AUTO_INCREMENT NOT NULL,\\\n",
    "   `bank_id` VARCHAR(255) NULL,\\\n",
    "   `link`  VARCHAR(255) NULL,\\\n",
    "   `company` VARCHAR(255) NOT NULL,\\\n",
    "   `position` VARCHAR(255) NOT NULL,\\\n",
    "   `area` VARCHAR(255)  NULL,\\\n",
    "   `salary_low` VARCHAR(255) NULL,\\\n",
    "   `salary_high` VARCHAR(255) NULL,\\\n",
    "   `industry` VARCHAR(255) NULL,\\\n",
    "   `content` VARCHAR(255)  NULL,\\\n",
    "   `requirement` VARCHAR(255) NULL,\\\n",
    "   `education` VARCHAR(255) NULL,\\\n",
    "   `applicant` VARCHAR(255) NULL,\\\n",
    "   `updated` VARCHAR(255) NULL,\\\n",
    "   `job_type`  VARCHAR(255) NULL,\\\n",
    "   `b_trip`  VARCHAR(255) NULL,\\\n",
    "   `manager`  VARCHAR(255) NULL,\\\n",
    "   `language`  VARCHAR(255) NULL,\\\n",
    "   `soft_skill`  VARCHAR(255) NULL,\\\n",
    "   `other_skill`  VARCHAR(255) NULL,\\\n",
    "    KEY (`id`),\\\n",
    "    CONSTRAINT job_id PRIMARY KEY (`company`,`position`)\\\n",
    "    )ENGINE=InnoDB DEFAULT CHARSET=utf8; \\\n",
    "    '''\n",
    "    \n",
    "    flag = check_table_exist(t_name)\n",
    "    if flag and new == 1:        #Table t_name已存在，建立新命名的table\n",
    "        t_name = \"new_\"+ t_name\n",
    "        table = table_start + t_name + table_end\n",
    "        cursor.execute(table)\n",
    "        conn.commit()  \n",
    "        cursor.close()      \n",
    "        conn.close()       \n",
    "    elif flag and new == 0:      #Table t_name已存在，不建立table\n",
    "        print(\"Table已存在!不建立新Table!\")\n",
    "        cursor.close()      \n",
    "        conn.close()       \n",
    "    else:                        #Table t_name不存在，直接建立table        \n",
    "        table = table_start + t_name + table_end\n",
    "        cursor.execute(table)\n",
    "        conn.commit()  \n",
    "        cursor.close()     #關閉 cursor 物件 \n",
    "        conn.close()       #關閉 conn 物件\n",
    "    \n",
    "# create_table(\"bigdata\",0)\n",
    "\n",
    "def toDatabase(job_list,t_name):\n",
    "    engine = create_engine('mysql+mysqlconnector://root:root@127.0.0.1:3306/job_bank?charset=utf8', encoding='utf-8')\n",
    "    con = engine.connect() #建立連結\n",
    "\n",
    "    for item in job_list:\n",
    "        df = pandas.DataFrame(item, index=[0]) # 為何加入index[0]:因為單次僅一個dict轉成df,詳情:https://reurl.cc/4gm4qD\n",
    "        try:\n",
    "            df.to_sql(t_name,con=con,if_exists='append', index=False) #假設table已存在 就自動往下加入data\n",
    "        except Exception as e:\n",
    "            if 'PRIMARY' in str(e):\n",
    "                pass\n",
    "    con.close() #關閉資料池連結\n",
    "    engine.dispose() #關閉資料庫連結\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=1\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=2\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=3\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=4\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=5\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=6\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=7\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=8\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=9\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=10\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=11\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=12\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=13\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=14\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=15\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=16\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=17\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=18\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=19\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=20\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=21\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=22\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=23\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=24\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=25\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=26\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=27\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=28\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=29\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=30\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=31\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=32\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=33\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=34\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=35\n",
      "https://www.104.com.tw/jobs/search/?ro=0&keyword=大數據&order=1&asc=0&page=36\n",
      "Table已存在!不建立新Table!\n"
     ]
    }
   ],
   "source": [
    "#呼叫爬蟲程式以及給予搜尋關鍵字和table名稱\n",
    "job_list = crawler(\"大數據\",\"bigdata\")\n",
    "          \n",
    "# XXX=table名稱\n",
    "# 當table名稱已存在時，new=1 -> 建立table new_XXX\n",
    "# 當table名稱已存在時，new=0 -> 不建立直接pass\n",
    "# 當table名稱不存在時，無論new=0 or 1 -> 直接建立table XXX\n",
    "create_table(\"bigdata\", new=0)\n",
    "\n",
    "#連結資料庫\n",
    "toDatabase(job_list,\"bigdata\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N/A\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'salary_high' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-fa6544302e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary_low\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary_high\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_trip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'salary_high' is not defined"
     ]
    }
   ],
   "source": [
    "#清理程式 v1.0\n",
    "import pandas as pd\n",
    "engine = engine = create_engine('mysql+mysqlconnector://root:root@127.0.0.1:3306/job_bank?charset=utf8', encoding='utf-8')\n",
    "with engine.connect() as con:\n",
    "    rs = con.execute(\"SELECT * FROM bigdata\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.columns = rs.keys()\n",
    "for index, row in df.iterrows(): \n",
    "    salary_low = row['salary_low']\n",
    "    b_trip = row['b_trip']\n",
    "    manager = row['manager']\n",
    "    language = row['language']\n",
    "\n",
    "    if salary_low  == \"待遇面議\": \n",
    "        salary_low = 'N/A'\n",
    "        salary_high = 0\n",
    "    elif \"元以上\" in salary_low:\n",
    "        salary_low = ''.join(x for x in salary_low if x.isdigit())\n",
    "        salary_high = 0\n",
    "    elif \"~\" in salary_low :\n",
    "        low = salary_low.split(\"~\")[0]\n",
    "        high = salary_low.split(\"~\")[1]\n",
    "        salary_low = ''.join(x for x in low if x.isdigit())\n",
    "        salary_high = ''.join(x for x in high if x.isdigit())\n",
    "    if b_trip == \"無需出差外派\":\n",
    "        b_trip = 'N'\n",
    "    else:\n",
    "         b_trip = 'Y'\n",
    "    if manager == \"不需負擔管理責任\":\n",
    "        manager = 'N'\n",
    "    else:\n",
    "         manager = 'Y'\n",
    "    if language == \"不拘\":\n",
    "        language = \"不拘\"\n",
    "    else:\n",
    "        language = language.split(\"--\")[0].strip()\n",
    "    print(salary_low)\n",
    "    print(salary_high)\n",
    "    print(b_trip)\n",
    "    print(manager)\n",
    "    print(language)\n",
    "# sql = 'update bigdata set salary_low = %s, salary_high = %d, b_trip = %s, manager =%s, language = %s'\n",
    "# con.execute(sql, (salary_low, salary_high, b_trip, manager))\n",
    "# con.commit()\n",
    "# con.close() #關閉資料池連結\n",
    "# engine.dispose() #關閉資料庫連結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_sql(\"select * from bigdata;\", engine)\n",
    "\n",
    "#update information (update your_table set column = \"new value\" where column = \"old value\")\n",
    "#still may need to iterate for many old value/new value pairs\n",
    "df[df['column'] == \"old value\", \"column\"] = \"new value\"\n",
    "\n",
    "#send data back to sql\n",
    "df.to_sql(\"your_table\", engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spider] *",
   "language": "python",
   "name": "conda-env-spider-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
